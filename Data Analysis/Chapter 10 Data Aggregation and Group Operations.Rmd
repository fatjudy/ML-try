---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.4.1
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

```{python}
import numpy as np
import pandas as pd
```

## GroupBy Mechanics

```{python}
df = pd.DataFrame({'key1': ['a', 'a', 'b', 'b', 'a'],
                  'key2' : ['one', 'two', 'one', 'two', 'one'],
                  'data1' : np.random.randn(5),
                  'data2' : np.random.randn(5)})
```

```{python}
df
```

```{python}
grouped = df['data1'].groupby(df['key1'])
```

```{python}
grouped # It is an groupby object
```

```{python}
grouped.mean()
```

```{python}
# multiple arrays as index
means = df['data1'].groupby([df['key1'], df['key2']]).mean()
```

```{python}
means
```

```{python}
means.unstack()
```

```{python}
df.groupby(['key1', 'key2']).mean()
```

### Iterating Over Groups

```{python}
for name, group in df.groupby('key1'):
    print(name)
    print(group)
```

```{python}
pieces = dict(list(df.groupby('key1')))
```

```{python}
pieces
```

### Selecting a Column or Subset of Columns

```{python}
df['data2'].groupby(df['key1'])
```

```{python}
df.groupby(['key1', 'key2'])['data2'].mean()
```

### Grouping with Dicts and Series

```{python}
people = pd.DataFrame(np.random.randn(5, 5),
....: columns=['a', 'b', 'c', 'd', 'e'],
....: index=['Joe', 'Steve', 'Wes', 'Jim', 'Travis'])
```

```{python}
people
```

```{python}
people.iloc[2:3, [1,2]] = np.nan
```

```{python}
people
```

```{python}
mapping = {'a': 'red', 'b': 'red', 'c': 'blue',
....: 'd': 'blue', 'e': 'red', 'f' : 'orange'} # unused grouping keys are ok: like 'f'
```

```{python}
by_column = people.groupby(mapping, axis = 1)
```

```{python}
by_column.sum()
```

```{python}
map_series = pd.Series(mapping)
```

```{python}
map_series
```

```{python}
people.groupby(map_series,axis = 1).count()
```

### Grouping with Functions

```{python}
# group by the length of name
people.groupby(len).sum()
```

```{python}
# # ?
key_list = ['one', 'one', 'one', 'two', 'two']
```

```{python}
people.groupby([len, key_list]).min()
```

### Grouping by Index Levels

```{python}
columns = pd.MultiIndex.from_arrays([['US', 'US', 'US', 'JP', 'JP'],
....: [1, 3, 5, 1, 3]],
....: names=['city', 'tenor'])
```

```{python}
hier_df = pd.DataFrame(np.random.randn(4,5), columns = columns)
```

```{python}
hier_df
```

```{python}
hier_df.groupby(level = 'city', axis = 1).count()
```

## 10.2 Data Aggregation

```{python}
def peak_to_peak (arr):
    return arr.max() - arr.min()
```

```{python}
grouped = df.groupby('key1')
```

```{python}
grouped.agg(peak_to_peak)
```

```{python}
group.describe()
```

### Column-Wise and Multiple Function Application

```{python}
tips = pd.read_csv('tips.csv')
```

```{python}
tips[:6]
```

```{python}
grouped = tips.groupby(['day', 'smoker'])
```

```{python}
grouped_tip = grouped['tip'] 

```

```{python}
grouped_tip.agg('mean')
```

```{python}
grouped_tip.agg(['mean', 'std', peak_to_peak])
```

```{python}
# if you pass a list of (name, function) tuples, the first element of each tuple will be used as the DataFrame column names 
grouped_tip.agg([('fool', 'mean'), ('bar', np.std)])
```

```{python}
functions = ['count', 'mean', 'max']
```

```{python}
result = grouped['tip', 'total_bill'].agg(functions)
```

```{python}
result
```

```{python}
ftuples = [('均值', 'mean'), ('Abweichung', np.var)]
```

```{python}
grouped['tip', 'total_bill'].agg(ftuples)
```

```{python}
grouped.agg({'tip' : ['min', 'max', 'mean', 'std'],'size' : 'sum'})
```

### Returning Aggregated Data Without Row Indexes

```{python}
tips.groupby(['day', 'smoker'], as_index = False).mean()
```

## 10.3 Apply: General split-apply-combine

```{python}
def top(df, n=5, column = 'tip'):
    return df.sort_values(by=column)[-n:]
```

```{python}
top(tips, n = 6, column = 'tip')
```

```{python}
tips.groupby(['smoker', 'day']).apply(top, n=1, column='tip')
```

```{python}
result = tips.groupby('smoker')['tip'].describe()
```

```{python}
result
```

```{python}
result.unstack('smoker')
```

```{python}
tips.groupby('smoker', group_keys=False).apply(top)
```

### Quantile and Bucket Analysis

```{python}
frame = pd.DataFrame({'data1': np.random.randn(1000),
....: 'data2': np.random.randn(1000)})
```

```{python}
quartiles = pd.cut(frame.data1, 4)
```

```{python}
def get_stats(group):
    return {'min': group.min(), 'max' : group.max(), 'count': group.count(), 'mean': group.mean()}
```

```{python}
grouped = frame.data2.groupby(quartiles)
```

```{python}
grouped
```

```{python}
grouped.apply(get_stats)  # ??
```

```{python}
grouping = pd.qcut(frame.data1, 10, labels=False)
```

```{python}
grouped = frame.data2.groupby(grouping)
```

```{python}
grouped.apply(get_stats).unstack()
```

### Example: Filling Missing Values with Group-Specific Values

```{python}
s = pd.Series(np.random.randn(6))
```

```{python}
s[::2] = np.nan
```

```{python}
s
```

```{python}
s.fillna(s.mean())
```

```{python}
 states = ['Ohio', 'New York', 'Vermont', 'Florida',
....: 'Oregon', 'Nevada', 'California', 'Idaho']
```

```{python}
group_key = ['East'] * 4 + ['West'] * 4
```

```{python}
data = pd.Series(np.random.randn(8), index = states)
```

```{python}
data
```

```{python}
data[['Vermont', 'Nevada', 'Idaho']] = np.nan
```

```{python}
data
```

```{python}
data.groupby(group_key).mean()
```

```{python}
fill_mean = lambda g: g.fillna(g.mean())
fill_mean = lambda g: g.fillna(g.mean())
```

```{python}
data.groupby(group_key).apply(fill_mean)
# data.groupby(group_key).apply(fill_mean)
```

```{python}
fill_values = {'East': 0.5, 'West': -1}
```

```{python}
# the groups have a name attribute set internally
fill_func = lambda g: g.fillna(fill_values[g.name])
```

```{python}
data.groupby(group_key).apply(fill_func)
# data.groupby(group_key).apply(fill_func)
```

### Example: Random Sampling and Permutation

```{python}
suits = ['H', 'S', 'C', 'D']
```

```{python}
card_val = (list(range(1,11)) + [10] * 3) * 4
```

```{python}
base_names = ['A'] + list(range(2,11)) + ['J', 'K', 'Q']
```

```{python}
cards = []
for suit in suits:
    cards.extend(str(num) + suit for num in base_names)
```

```{python}
deck = pd.Series(card_val, index = cards)
```

```{python}
deck.sample(5)
```

```{python}
def draw(deck, n):
    return deck.sample(n)
```

```{python}
get_suit = lambda card: card[-1]
```

```{python}
deck.groupby(get_suit).apply(draw, n = 2)
```

```{python}
deck.groupby(get_suit, group_keys=False).apply(draw, n=2)
```

### Example: Group Weighted Average and Correlation

```{python}
df = pd.DataFrame({'category': ['a', 'a', 'a', 'a',
.....: 'b', 'b', 'b', 'b'],
.....: 'data': np.random.randn(8),
.....: 'weights': np.random.rand(8)})
```

```{python}
df
```

```{python}
grouped = df.groupby('category')
```

```{python}
get_wavg = lambda g: np.average(g['data'], weights = g['weights'])
```

```{python}
grouped.apply(get_wavg)
```

```{python}
close_px = pd.read_csv('stock_px.csv', parse_dates = True, index_col = 0)
```

```{python}
close_px.head()
```

```{python}
spx_corr = lambda x: x.corrwith(x['SPX'])
```

```{python}
res = close_px.pct_change().dropna()
```

```{python}
get_year = lambda x: x.year
```

```{python}
by_year = res.groupby(get_year)
```

```{python}
by_year.apply(spx_corr)
```

```{python}
by_year.apply(lambda g: g['AAPL'].corr(g['MSFT']))
```

```{python}
import statsmodels.api as sm
def regress(data, yvar, xvars):
    Y = data[yvar]
    X = data[xvars]
    X['intercept'] = 1.
    result = sm.OLS(Y, X).fit()
    return result.params
```

```{python}
by_year.apply(regress, 'AAPL', ['SPX'])
```

## 10.4 Pivot Tables and Cross-Tabulation

```{python}
tips.pivot_table(index=['day', 'smoker', 'tip'])
```

```{python}
tips.pivot_table(['tip', 'size'], index = ['time', 'day'], columns = 'smoker')
```

```{python}
# # margin??
tips.pivot_table(['tip', 'size'], index=['time', 'day'], columns='smoker', margins=True)
```

```{python}
tips.pivot_table('tip', index=['time', 'smoker'], columns='day',aggfunc = len, margins = True)
```

```{python}
tips.pivot_table('tip', index=['time', 'size', 'smoker'], columns='day', aggfunc='mean', fill_value=0)

```

### Cross-Tabulations: Crosstab

```{python}
pd.crosstab([tips.time, tips.day], tips.smoker, margins=True)
```

```{python}

```
