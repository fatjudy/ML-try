---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.4.1
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

# Chapter 14 Data Analysis Examples

```{python}
import numpy as np
```

```{python}
path = '14 dataset/example.txt'
```

```{python}
open(path).readline()
```

```{python}
import json
```

```{python}
records = [json.loads(line) for line in open(path)]
```

```{python}
records[0]
```

```{python}
len(records)
```

```{python}
records[0]['tz']
```

```{python}
# This will fail because not all records have 'tz'
time_zones = [rec['tz'] for rec in records]
```

```{python}
time_zones = [rec['tz'] for rec in records if 'tz' in rec]
```

```{python}
time_zones[:5]
```

```{python}
import pandas as pd
```

```{python}
frame = pd.DataFrame(records)
```

```{python}
frame.info()
```

```{python}
top10_tz_counts = frame['tz'].value_counts()[:10]
```

```{python}
top10_tz_counts
```

```{python}
clean_tz = frame['tz'].fillna('Missing')
```

```{python}
clean_tz[clean_tz == ''] = 'Unknown'
```

```{python}
tz_cleaned = clean_tz.value_counts()
```

```{python}
tz_cleaned[:10]
```

```{python}
import seaborn as sns
```

```{python}
sns.barplot(y = tz_cleaned[:10].index, x = tz_cleaned[:10].values)
```

```{python}
frame.head()
```

```{python}
len(frame['a'][1])
```

```{python}
string_result = pd.Series([x.split()[0] for x in frame.a.dropna()])
```

```{python}
string_result[:5]
```

```{python}
string_result.value_counts()[:5]
```

```{python}
cframe = frame[frame.a.notnull()]
```

```{python}
cframe['os'] = np.where(cframe['a'].str.contains('Windows'), 'Windows', 'Not Windows')
```

```{python}
cframe.head()
```

```{python}
by_tz_os = cframe.groupby(['tz', 'os'])
```

```{python}
by_tz_os
```

```{python}
agg_counts = by_tz_os.size().unstack().fillna(0)
```

```{python}
agg_counts[:5]
```

```{python}
agg_counts.sum(1).nlargest(10)
```

```{python}
indexer = agg_counts.sum(1).argsort()
```

```{python}
indexer[:10]
```

```{python}
count_subset = agg_counts.take(indexer[-10:])
```

```{python}
count_subset
```

```{python}
count_subset = count_subset.stack()
```

```{python}
count_subset
```

```{python}
count_subset.name = 'Total'
```

```{python}
count_subset = count_subset.reset_index()
```

```{python}
sns.barplot(x = 'Total', y = 'tz', hue = 'os', data = count_subset)
```

```{python}
count_subset
```

```{python}
grouped = count_subset.groupby('tz')
```

```{python}
for name_of_the_group, group in grouped.Total:
#    print (name_of_the_group)
   print (group)
```

```{python}
def norm_total(group):
    group['normed_total'] = group.Total / group.Total.sum()
    return group
```

```{python}
results = count_subset.groupby('tz').apply(norm_total)
```

```{python}
results
```

```{python}
sns.barplot(x='normed_total', y='tz', hue='os', data=results)
```

## 14.2 MovieLens 1M Dataset

```{python}
# url = 'https://github.com/wesm/pydata-book/blob/2nd-edition/datasets/movielens/users.dat'
url = 'https://raw.githubusercontent.com/wesm/pydata-book/2nd-edition/datasets/movielens/users.dat'
unames = ['user_id', 'gender', 'age', 'occupation', 'zip']
users = pd.read_table(url, sep='::', header=None, names=unames)
```

```{python}
users[:5]
```

```{python}
url = 'https://raw.githubusercontent.com/wesm/pydata-book/2nd-edition/datasets/movielens/ratings.dat'
rnames = ['user_id', 'movie_id', 'rating', 'timestamp']
ratings = pd.read_table(url, sep='::', header=None, names=rnames)
```

```{python}
ratings[:5]
```

```{python}
url = 'https://raw.githubusercontent.com/wesm/pydata-book/2nd-edition/datasets/movielens/movies.dat'
mnames = ['movie_id', 'title', 'genres']
movies = pd.read_table(url, sep='::', header=None, names=mnames)
```

```{python}
movies[:5]
```

```{python}
users.shape
```

```{python}
ratings.shape
```

```{python}
movies.shape
```

```{python}
data = pd.merge(pd.merge(ratings, users), movies)
```

```{python}
data
```

```{python}
data.iloc[0]
```

```{python}
mean_rating = data.pivot_table('rating', index = 'title', columns = 'gender', aggfunc = 'mean')
```

```{python}
mean_rating.nlargest(10, 'F')
```

```{python}
mean_rating.nlargest(10, 'M')
```

```{python}
mean_rating[mean_rating['M'] == mean_rating['F']]
```

```{python}
ratings_by_title = data.groupby('title').size()
```

```{python}
ratings_by_title
```

```{python}
active_titles = ratings_by_title.index[ratings_by_title > 250]
```

```{python}
active_titles
```

```{python}
mean_rating = mean_rating.loc[active_titles]
```

```{python}
top_female_ratings = mean_rating.sort_values(by='F', ascending=False)
```

```{python}
top_female_ratings
```

```{python}
mean_rating['diff'] = mean_rating['M'] - mean_rating['F']
```

```{python}
sort_by_diff = mean_rating.sort_values(by = 'diff')
```

```{python}
sort_by_diff[:10]
```

```{python}
sort_by_diff[::-1][:10]
```

```{python}
rating_std_by_title = data.groupby('title')['rating'].std()
```

```{python}
rating_std_by_title[:5]
```

```{python}
rating_std_by_title = rating_std_by_title.loc[active_titles]
```

```{python}
rating_std_by_title.sort_values(ascending = False)[:10]
```

## 14.3 US Baby Names 1880â€“2010

```{python}

```
