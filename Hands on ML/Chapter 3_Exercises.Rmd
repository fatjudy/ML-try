---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.4.1
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

```{python}
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.neighbors import KNeighborsClassifier
```

```{python}
from sklearn.datasets import fetch_openml
```

```{python}
mnist = fetch_openml("MNIST_784")
```

```{python}
X, y = mnist['data'], mnist['target']
```

```{python}
X.shape, y.shape
```

```{python}
import matplotlib
```

```{python}
import matplotlib.pyplot as plt
```

```{python}
plt.imshow(X[300].reshape(28,28), cmap = matplotlib.cm.binary)
```

```{python}
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 20)
```

```{python}
neighbors = KNeighborsClassifier()
```

```{python}
neighbors.fit(X_train, y_train)
```

```{python}
neighbors.predict([X[300]])
```

```{python}
cross_val_score(neighbors, X_train, y_train, cv = 3, scoring = "accuracy")
# Three numbers means score for 3 different folds
```

```{python}
neighbors.score(X_train, y_train)
```

```{python}
from sklearn.model_selection import GridSearchCV
param_grid = [{'n_neighbors': [3,5,7,11], 'weights': ['uniform', 'distance']}]
knn_clf = KNeighborsClassifier()
grid_search = GridSearchCV(knn_clf, param_grid, verbose = 3, cv = 3, n_jobs = -1)
grid_search.fit(X_train, y_train)
```

```{python}
grid_search.best_params_
```

```{python}
grid_search.best_score_
```

```{python}
grid_search.fit(X_train, y_train)
```

```{python}
from sklearn.metrics import accuracy_score
y_pred = grid_search.predict(X_test)
accuracy_score(y_test, y_pred)
```

```{python}
# Data Augmentation
```

```{python}
from scipy.ndimage.interpolation import shift

```

```{python}
def shift_image(image, dx, dy):
    image = image.reshape(28, 28)
    shifted_image = shift(image, shift = [dy, dx], cval = 0, mode = 'constant')
    return shifted_image.reshape([-1])
```

```{python}
X_train_augmented = [image for image in X_train]
y_train_augmented = [label for label in y_train]
```

```{python}
for dy, dx in ((1,0), (0,1), (-1,0), (0,-1)):
    for image, label in zip(X_train, y_train):
        X_train_augmented.append(shift_image(image, dy, dx))
        y_train_augmented.append(label)
```

```{python}
import numpy as np
```

```{python}
X_train_more = np.array(X_train_augmented)
y_train_more = np.array(y_train_augmented)
```

```{python}
# shuffle index
shuffle_idx = np.random.permutation(len(X_train_more))
X_train_new = X_train_more[shuffle_idx]
y_train_new = y_train_more[shuffle_idx]
```

```{python}
y_train_new
```

```{python}
knn_clf = KNeighborsClassifier(**grid_search.best_params_)
```

```{python}
knn_clf.fit(X_train_new, y_train_new)
```

```{python}
from sklearn.metrics import accuracy_score
```

```{python}
y_pred = knn_clf.predict(X_test)
```

```{python}
accuracy_score(y_test, y_pred)
```

```{python}
# Tatanic Dataset
```

```{python}
# import requests, os
```

```{python}
# url_train = 'https://www.kaggle.com/c/titanic/data?select=train.csv'
# url_test = 'https://www.kaggle.com/c/titanic/data?select=test.csv'
# titanic_path = 'C:/Users/yzho0040/Python_Basic/Hands on ML/datasets/Titanic'
```

```{python}
# def fetch_titanic_data(url, path, name):
#     if not os.path.isdir(path):
#         os.makedirs(path)
#     save_path = os.path.join(path, name)
#     file = requests.get(url)
#     with open(save_path, 'wb') as output:
#         output.write(file.content)
#     print("Done!")
```

```{python}
# fetch_titanic_data(url_train, path = titanic_path, name = 'train.csv')
# fetch_titanic_data(url_test, path = titanic_path, name = 'test.csv')
```

```{python}
import pandas as pd
import numpy as np
```

```{python}
def load_data(filename):
    path = os.path.join('datasets', 'titanic')
    csv_path = os.path.join(path, filename)
    return pd.read_csv(csv_path)
```

```{python}
train = load_data('train.csv')
```

```{python}
train.info()
```

```{python}
train.describe()
# We can see the surviving rate is less than 39%
# Also we can see mean age and mean fare
```

```{python}
train.head()
```

```{python}
# use value_counts() to see values in different categories
train['Pclass'].value_counts()
```

```{python}
# Plots 
```

```{python}
# Build pipelines
```

```{python}
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.impute import SimpleImputer
```

```{python}
class DF_Selector(BaseEstimator, TransformerMixin):
    def __init__(self, attribute_names):
        self.attribute_names = attribute_names
    def fit(self, X, y = None):
        return self
    def transform(self, X):
        return X[self.attribute_names]
```

```{python}
from sklearn.pipeline import Pipeline
```

```{python}
num_pipeline= Pipeline([
    ("select_numeric", DF_Selector(['Age', 'SibSp', 'Parch', 'Fare'])),
    ("imputer", SimpleImputer(strategy = 'median')),
])
```

```{python}
train_transformed = num_pipeline.fit_transform(train)
```

```{python}
train_transformed.shape
```

```{python}
class MostFrequentImputer(BaseEstimator, TransformerMixin):
    def fit(self, X, y = None):
        self.most_frequent_ = pd.Series([X[c].value_counts() .index[0] for c in X], index = X.columns)
        return self
    def transform(self, X, y = None):
        return (X.fillna(self.most_frequent_))
```

```{python}
from sklearn.preprocessing import OneHotEncoder
```

```{python}
cat_pipeline = Pipeline([
    ("select_cat", DF_Selector(['Pclass', 'Sex', 'Embarked'])),
    ("imputer", MostFrequentImputer()),
    ("cat_encoder", OneHotEncoder(sparse = False))
])
```

```{python}
cat_pipeline.fit_transform(train)
```

```{python}
from sklearn.pipeline import FeatureUnion
```

```{python}
preprocess_pipeline = FeatureUnion(transformer_list = [
    ("num_pipeline", num_pipeline),
    ("cat_pipeline", cat_pipeline),
])
```

```{python}
X_train = preprocess_pipeline.fit_transform(train)
```

```{python}
y_train = train['Survived']
```

```{python}
from sklearn.svm import SVC
```

```{python}
svm_clf = SVC(gamma = 'auto')
svm_clf.fit(X_train, y_train)
```

```{python}
test = load_data('test.csv')
```

```{python}
X_test = preprocess_pipeline.transform(test)
```

```{python}
y_pred = svm_clf.predict(X_test)
```

```{python}
from sklearn.model_selection import cross_val_score
```

```{python}
svm_scores = cross_val_score(svm_clf, X_train, y_train, cv = 10)
```

```{python}
svm_scores.mean()
```

```{python}
# Another model
```

```{python}
from sklearn.ensemble import RandomForestClassifier
```

```{python}
forest_clf = RandomForestClassifier(n_estimators=100, random_state=20)
forest_scores = cross_val_score(forest_clf, X_train, y_train, cv=10)
forest_scores.mean()
```

```{python}
# Visualization
plt.figure(figsize = (8,4))
plt.plot([1]*10, svm_scores, ".")
plt.plot([2]*10, forest_scores, ".")
plt.boxplot([svm_scores, forest_scores], labels = ("SVM", "Random Forest"))
plt.ylabel("Accuracy", fontsize = 12)
```

```{python}
train['Age Bucket'] = train['Age'] // 15 *15
```

```{python}
train[['Age Bucket', 'Survived']].groupby(['Age Bucket']).mean()
```

```{python}
train['Relative'] = train['SibSp'] + train['Parch']
```

```{python}
train[['Relative', 'Survived']].groupby(['Relative']).mean()
```

```{python}
# Spam Classifier
```

```{python}
import os
import tarfile
from six.moves import urllib

DOWNLOAD_ROOT = "http://spamassassin.apache.org/old/publiccorpus/"
HAM_URL = DOWNLOAD_ROOT + "20030228_easy_ham.tar.bz2"
SPAM_URL = DOWNLOAD_ROOT + "20030228_spam.tar.bz2"
SPAM_PATH = os.path.join("datasets", "spam")

def fetch_spam_data(spam_url=SPAM_URL, spam_path=SPAM_PATH):
    if not os.path.isdir(spam_path):
        os.makedirs(spam_path)
    for filename, url in (("ham.tar.bz2", HAM_URL), ("spam.tar.bz2", SPAM_URL)):
        path = os.path.join(spam_path, filename)
        if not os.path.isfile(path):
            urllib.request.urlretrieve(url, path)
        tar_bz2_file = tarfile.open(path)
        tar_bz2_file.extractall(path=SPAM_PATH)
        tar_bz2_file.close()
```

```{python}
fetch_spam_data()
```

```{python}
os.path.isfile(os.path.join(SPAM_PATH, "tt.tar.bz2"))
```

```{python}
os.path.join(SPAM_PATH, "easy_ham")
```

```{python}
sorted(os.path.join(SPAM_PATH, "easy_ham"))
```

```{python}

```
