---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.4.1
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

```{python}
from sklearn.metrics import mean_squared_error
```

```{python}
from sklearn.linear_model import LogisticRegression
```

```{python}
best_epoch = None
best_model = None
```

```{python}
from sklearn.model_selection import train_test_split
```

```{python}
from sklearn import datasets
```

```{python}
iris = datasets.load_iris()
```

```{python}
X, y = iris['data'][:, (2, 3)], iris['target']
```

```{python}
X_train, X_test ,y_train, y_test = train_test_split(X, y,test_size = 0.2, random_state = 30)
```

```{python}
import numpy as np
```

```{python}
np.zeros((2,3))
```

```{python}
def onehot(y):
    N = y.max() + 1
    m = len(y)
    matrix = np.zeros((m, N))
    matrix[np.arange(m), y] = 1
    return matrix
```

```{python}
y_test = onehot(y_test)
```

```{python}
y_train = onehot(y_train)
```

```{python}
def softmax(logits):
    exps = np.exp(logits)
    exp_sums = np.sum(exps, axis = 1, keepdims = True)
    return exps/exp_sums
```

```{python}
X_new = np.c_[np.ones([len(X),1]), X]
```

```{python}
X_train, X_test ,y_train, y_test = train_test_split(X_new, y,test_size = 0.2, random_state = 30)
```

```{python}
n_inputs = X_train.shape[1]
```

```{python}
n_outputs = len(np.unique(y))
```

```{python}
n_inputs = X_train.shape[1] # == 3 (2 features plus the bias term)
n_outputs = len(np.unique(y_train))   # == 3 (3 iris classes)
```

```{python}
Theta = np.random.randn(n_inputs, n_outputs)
```

```{python}
def softmax(logits):
    exps = np.exp(logits)
    exp_sums = np.sum(exps, axis=1, keepdims=True)
    return exps / exp_sums
```

```{python}
logits = X_train.dot(Theta)
```

```{python}
Y_proba = softmax(logits)
```

```{python}
y_train*Y_proba
```

```{python}
Y_proba.shape
```

```{python}
exp_sum = np.sum(exps, axis = 1,keepdims = True)
```

```{python}
p = exps/exp_sum
```

```{python}
p
```

```{python}
y_train.reshape(-1,1)*np.log(p)
```

```{python}

```
